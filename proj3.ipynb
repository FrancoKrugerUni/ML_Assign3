{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "setup_imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import (\n",
        "    load_iris,\n",
        "    load_wine,\n",
        "    load_breast_cancer,\n",
        "    load_diabetes,\n",
        "    make_friedman1,\n",
        "    make_regression\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "load_data",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "iris_data = load_iris()\n",
        "iris_X, iris_y = iris_data.data, iris_data.target\n",
        "\n",
        "wine_data = load_wine()\n",
        "wine_X, wine_y = wine_data.data, wine_data.target\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "cancer_X, cancer_y = cancer_data.data, cancer_data.target\n",
        "\n",
        "diabetes_data = load_diabetes()\n",
        "diabetes_X, diabetes_y = diabetes_data.data, diabetes_data.target\n",
        "\n",
        "friedman_X, friedman_y = make_friedman1(n_samples=500, n_features=10, noise=0.1, random_state=1)\n",
        "\n",
        "synth_X, synth_y = make_regression(n_samples=500, n_features=15, n_informative=10, noise=0.1, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "prep_datasets",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split and scale iris\n",
        "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(\n",
        "    iris_X, iris_y, test_size=0.2, random_state=1, stratify=iris_y\n",
        ")\n",
        "scaler1 = StandardScaler()\n",
        "iris_X_train = scaler1.fit_transform(iris_X_train)\n",
        "iris_X_test = scaler1.transform(iris_X_test)\n",
        "\n",
        "\n",
        "wine_X_train, wine_X_test, wine_y_train, wine_y_test = train_test_split(\n",
        "    wine_X, wine_y, test_size=0.2, random_state=1, stratify=wine_y\n",
        ")\n",
        "scaler2 = StandardScaler()\n",
        "wine_X_train = scaler2.fit_transform(wine_X_train)\n",
        "wine_X_test = scaler2.transform(wine_X_test)\n",
        "\n",
        "\n",
        "cancer_X_train, cancer_X_test, cancer_y_train, cancer_y_test = train_test_split(\n",
        "    cancer_X, cancer_y, test_size=0.2, random_state=1, stratify=cancer_y\n",
        ")\n",
        "scaler3 = StandardScaler()\n",
        "cancer_X_train = scaler3.fit_transform(cancer_X_train)\n",
        "cancer_X_test = scaler3.transform(cancer_X_test)\n",
        "\n",
        "\n",
        "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(\n",
        "    diabetes_X, diabetes_y, test_size=0.2, random_state=1\n",
        ")\n",
        "scaler4 = StandardScaler()\n",
        "diabetes_X_train = scaler4.fit_transform(diabetes_X_train)\n",
        "diabetes_X_test = scaler4.transform(diabetes_X_test)\n",
        "\n",
        "\n",
        "friedman_X_train, friedman_X_test, friedman_y_train, friedman_y_test = train_test_split(\n",
        "    friedman_X, friedman_y, test_size=0.2, random_state=1\n",
        ")\n",
        "scaler5 = StandardScaler()\n",
        "friedman_X_train = scaler5.fit_transform(friedman_X_train)\n",
        "friedman_X_test = scaler5.transform(friedman_X_test)\n",
        "\n",
        "\n",
        "synth_X_train, synth_X_test, synth_y_train, synth_y_test = train_test_split(\n",
        "    synth_X, synth_y, test_size=0.2, random_state=1\n",
        ")\n",
        "scaler6 = StandardScaler()\n",
        "synth_X_train = scaler6.fit_transform(synth_X_train)\n",
        "synth_X_test = scaler6.transform(synth_X_test)\n",
        "\n",
        "\n",
        "# Scale regression targets\n",
        "target_scaler_diabetes = StandardScaler()\n",
        "diabetes_y_train = target_scaler_diabetes.fit_transform(diabetes_y_train.reshape(-1,1)).flatten()\n",
        "diabetes_y_test = target_scaler_diabetes.transform(diabetes_y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "target_scaler_friedman = StandardScaler()\n",
        "friedman_y_train = target_scaler_friedman.fit_transform(friedman_y_train.reshape(-1,1)).flatten()\n",
        "friedman_y_test = target_scaler_friedman.transform(friedman_y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "target_scaler_synth = StandardScaler()\n",
        "synth_y_train = target_scaler_synth.fit_transform(synth_y_train.reshape(-1,1)).flatten()\n",
        "synth_y_test = target_scaler_synth.transform(synth_y_test.reshape(-1,1)).flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "net_function",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_net(input_dim, hidden_dim, output_dim):\n",
        "    layers = []\n",
        "    layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "    layers.append(nn.ReLU())\n",
        "    layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def train_net(net, X_data, y_data, lr=0.01, epochs=100, is_classification=True):\n",
        "    X_tensor = torch.FloatTensor(X_data)\n",
        "    \n",
        "    if is_classification:\n",
        "        y_tensor = torch.LongTensor(y_data)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        y_tensor = torch.FloatTensor(y_data).reshape(-1, 1)\n",
        "        loss_fn = nn.MSELoss()\n",
        "    \n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    \n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(X_tensor)\n",
        "        loss = loss_fn(outputs, y_tensor)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "    \n",
        "    return net\n",
        "\n",
        "def test_net(net, X_test, y_test, is_classification=True,  target_scaler=None):\n",
        "    net.eval()\n",
        "    X_tensor = torch.FloatTensor(X_test)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = net(X_tensor)\n",
        "        \n",
        "        if is_classification:\n",
        "            preds = torch.argmax(outputs, dim=1).numpy()\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            return acc\n",
        "        else:\n",
        "            preds = outputs.numpy().flatten()\n",
        "            if target_scaler is not None:\n",
        "                preds_unscaled = target_scaler.inverse_transform(preds.reshape(-1,1)).flatten()\n",
        "                y_test_unscaled = target_scaler.inverse_transform(np.array(y_test).reshape(-1,1)).flatten()\n",
        "                mse_unscaled = mean_squared_error(y_test_unscaled, preds_unscaled)\n",
        "                return mse_unscaled\n",
        "            else:\n",
        "                mse = mean_squared_error(y_test, preds)\n",
        "                return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "query_methods",
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_query(net, pool_X, pool_y, n_query=1):\n",
        "    idxs = np.random.choice(len(pool_X), size=min(n_query, len(pool_X)), replace=False)\n",
        "    return idxs\n",
        "\n",
        "def sasla_query(net, pool_X, pool_y, beta=0.8, n_query=1):\n",
        "    net.eval()\n",
        "    X_tensor = torch.FloatTensor(pool_X)\n",
        "    print('Sasla running...')\n",
        "    sensitivity_scores = []\n",
        "\n",
        "    for i in range(len(pool_X)):\n",
        "        x = X_tensor[i:i+1].clone().detach().requires_grad_(True)\n",
        "        output = net(x)\n",
        "\n",
        "        # Jacobian\n",
        "        jac = []\n",
        "        for j in range(output.shape[1]):\n",
        "            grad_outputs = torch.zeros_like(output)\n",
        "            grad_outputs[0, j] = 1\n",
        "            grad = torch.autograd.grad(\n",
        "                outputs=output,\n",
        "                inputs=x,\n",
        "                grad_outputs=grad_outputs,\n",
        "                retain_graph=True,\n",
        "                create_graph=False\n",
        "            )[0]\n",
        "            jac.append(grad.view(-1))\n",
        "        jac = torch.stack(jac)  # shape\n",
        "\n",
        "        # output sensitivity\n",
        "        output_sens_vec = torch.sum(torch.abs(jac), dim=1)\n",
        "\n",
        "        # informativeness\n",
        "        informativeness = torch.max(torch.abs(output_sens_vec))\n",
        "        sensitivity_scores.append(informativeness.item())\n",
        "\n",
        "    sensitivity_scores = np.array(sensitivity_scores)\n",
        "\n",
        "    # threshold\n",
        "    mean_sens = np.mean(sensitivity_scores)\n",
        "    thresh = (1.0 - beta) * mean_sens\n",
        "\n",
        "    candidates = np.where(sensitivity_scores > thresh)[0]\n",
        "    if len(candidates) == 0:\n",
        "        candidates = [np.argmax(sensitivity_scores)]\n",
        "\n",
        "    #selected = np.random.choice(candidates, size=min(n_query, len(candidates)), replace=False)\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def alus_query(net, pool_X, pool_y, t_param=20, n_query=1):\n",
        "    net.eval()\n",
        "    X_tensor = torch.FloatTensor(pool_X)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = net(X_tensor)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        entropy_vals = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)\n",
        "    \n",
        "    uncertain_idxs = torch.topk(entropy_vals, min(t_param, len(entropy_vals))).indices\n",
        "    \n",
        "    conflict_scores = []\n",
        "    for idx in uncertain_idxs:\n",
        "        prob_vec = probs[idx]\n",
        "        top2_vals = torch.topk(prob_vec, 2)\n",
        "        \n",
        "        # Get score\n",
        "        with torch.no_grad():\n",
        "            hidden_output = net[0](X_tensor[idx:idx+1])\n",
        "            hidden_output = net[1](hidden_output)  # RELU\n",
        "            final_weights = net[2].weight\n",
        "            \n",
        "            evidence1 = torch.sum(torch.relu(final_weights[top2_vals.indices[0]] * hidden_output))\n",
        "            evidence2 = torch.sum(torch.relu(final_weights[top2_vals.indices[1]] * hidden_output))\n",
        "            conflict_score = evidence1 * evidence2\n",
        "        \n",
        "        conflict_scores.append((idx.item(), conflict_score.item()))\n",
        "    \n",
        "    conflict_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    selected = [conflict_scores[i][0] for i in range(min(n_query, len(conflict_scores)))]\n",
        "    return np.array(selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "run_experiment",
      "metadata": {},
      "outputs": [],
      "source": [
        "def do_active_learning(X_train, y_train, X_test, y_test, query_func, \n",
        "                      initial_samples=10, budget=50, hidden_size=50, \n",
        "                      lr=0.01, epochs=100, is_classification=True, target_scaler=None):\n",
        "    \n",
        "    labeled_idxs = np.random.choice(len(X_train), size=initial_samples, replace=False)\n",
        "    unlabeled_idxs = np.setdiff1d(np.arange(len(X_train)), labeled_idxs)\n",
        "    \n",
        "    performance_list = []\n",
        "    sizes_list = []\n",
        "    \n",
        "    for iter_num in range(budget):\n",
        "        if is_classification:\n",
        "            n_classes = len(np.unique(y_train))\n",
        "        else:\n",
        "            n_classes = 1\n",
        "        \n",
        "        net = make_net(X_train.shape[1], hidden_size, n_classes)\n",
        "        net = train_net(net, X_train[labeled_idxs], y_train[labeled_idxs], \n",
        "                       lr=lr, epochs=epochs, is_classification=is_classification)\n",
        "        \n",
        "        target_scaler = target_scaler_diabetes\n",
        "        perf = test_net(net, X_test, y_test, is_classification=is_classification, target_scaler=target_scaler)\n",
        "        performance_list.append(perf)\n",
        "        sizes_list.append(len(labeled_idxs))\n",
        "        \n",
        "        if len(unlabeled_idxs) == 0:\n",
        "            break\n",
        "        \n",
        "        selected = query_func(net, X_train[unlabeled_idxs], y_train[unlabeled_idxs])\n",
        "        \n",
        "        new_labeled = unlabeled_idxs[selected]\n",
        "        labeled_idxs = np.concatenate([labeled_idxs, new_labeled])\n",
        "        unlabeled_idxs = np.setdiff1d(unlabeled_idxs, new_labeled)\n",
        "    \n",
        "    return sizes_list, performance_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "iris_experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "iris_passive_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(iris_X_train, iris_y_train, iris_X_test, iris_y_test, \n",
        "                                   random_query, initial_samples=10, budget=40, \n",
        "                                   hidden_size=30, lr=0.01, epochs=100, is_classification=True)\n",
        "    iris_passive_results.append((sizes, perf))\n",
        "\n",
        "iris_sasla_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(iris_X_train, iris_y_train, iris_X_test, iris_y_test, \n",
        "                                   sasla_query, initial_samples=10, budget=40, \n",
        "                                   hidden_size=30, lr=0.01, epochs=100, is_classification=True)\n",
        "    iris_sasla_results.append((sizes, perf))\n",
        "\n",
        "iris_alus_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(iris_X_train, iris_y_train, iris_X_test, iris_y_test, \n",
        "                                   alus_query, initial_samples=10, budget=40, \n",
        "                                   hidden_size=30, lr=0.01, epochs=100, is_classification=True)\n",
        "    iris_alus_results.append((sizes, perf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "wine_experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wine_passive_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(wine_X_train, wine_y_train, wine_X_test, wine_y_test, \n",
        "                                   random_query, initial_samples=10, budget=50, \n",
        "                                   hidden_size=70, lr=0.01, epochs=100, is_classification=True)\n",
        "    wine_passive_results.append((sizes, perf))\n",
        "\n",
        "\n",
        "wine_sasla_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(wine_X_train, wine_y_train, wine_X_test, wine_y_test, \n",
        "                                   sasla_query, initial_samples=10, budget=50, \n",
        "                                   hidden_size=70, lr=0.01, epochs=100, is_classification=True)\n",
        "    wine_sasla_results.append((sizes, perf))\n",
        "\n",
        "\n",
        "wine_alus_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(wine_X_train, wine_y_train, wine_X_test, wine_y_test, \n",
        "                                   alus_query, initial_samples=10, budget=50, \n",
        "                                   hidden_size=70, lr=0.01, epochs=100, is_classification=True)\n",
        "    wine_alus_results.append((sizes, perf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cancer_experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cancer_passive_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(cancer_X_train, cancer_y_train, cancer_X_test, cancer_y_test, \n",
        "                                   random_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=70, lr=0.01, epochs=100, is_classification=True)\n",
        "    cancer_passive_results.append((sizes, perf))\n",
        "\n",
        "\n",
        "cancer_sasla_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(cancer_X_train, cancer_y_train, cancer_X_test, cancer_y_test, \n",
        "                                   sasla_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=70, lr=0.01, epochs=100, is_classification=True)\n",
        "    cancer_sasla_results.append((sizes, perf))\n",
        "\n",
        "\n",
        "cancer_alus_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(cancer_X_train, cancer_y_train, cancer_X_test, cancer_y_test, \n",
        "                                   alus_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=70, lr=0.01, epochs=100, is_classification=True)\n",
        "    cancer_alus_results.append((sizes, perf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "diabetes_experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "diabetes_passive_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(diabetes_X_train, diabetes_y_train, diabetes_X_test, diabetes_y_test, \n",
        "                                   random_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=50, lr=0.01, epochs=100, is_classification=False,target_scaler=target_scaler_diabetes)\n",
        "    diabetes_passive_results.append((sizes, perf))\n",
        "\n",
        "diabetes_sasla_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(diabetes_X_train, diabetes_y_train, diabetes_X_test, diabetes_y_test, \n",
        "                                   sasla_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=50, lr=0.01, epochs=100, is_classification=False,target_scaler=target_scaler_diabetes)\n",
        "    diabetes_sasla_results.append((sizes, perf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "friedman_experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "friedman_passive_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(friedman_X_train, friedman_y_train, friedman_X_test, friedman_y_test, \n",
        "                                   random_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=70, lr=0.005, epochs=100, is_classification=False,target_scaler=target_scaler_diabetes)\n",
        "    friedman_passive_results.append((sizes, perf))\n",
        "\n",
        "friedman_sasla_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(friedman_X_train, friedman_y_train, friedman_X_test, friedman_y_test, \n",
        "                                   sasla_query, initial_samples=20, budget=100, \n",
        "                                   hidden_size=70, lr=0.005, epochs=100, is_classification=False,target_scaler=target_scaler_diabetes)\n",
        "    friedman_sasla_results.append((sizes, perf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "synth_experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n",
            "Sasla running...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "synth_passive_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(synth_X_train, synth_y_train, synth_X_test, synth_y_test, \n",
        "                                   random_query, initial_samples=50, budget=100, \n",
        "                                   hidden_size=50, lr=0.01, epochs=100, is_classification=False,target_scaler=target_scaler_diabetes)\n",
        "    synth_passive_results.append((sizes, perf))\n",
        "\n",
        "synth_sasla_results = []\n",
        "for trial in range(5):\n",
        "    np.random.seed(trial)\n",
        "    torch.manual_seed(trial)\n",
        "    sizes, perf = do_active_learning(synth_X_train, synth_y_train, synth_X_test, synth_y_test, \n",
        "                                   sasla_query, initial_samples=50, budget=100, \n",
        "                                   hidden_size=50, lr=0.01, epochs=100, is_classification=False,target_scaler=target_scaler_diabetes)\n",
        "    synth_sasla_results.append((sizes, perf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot_results",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "print_summary",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iris:\n",
            "Passive: 0.7667 pm 0.0558\n",
            "SASLA: 0.7133 pm 0.0499\n",
            "ALUS: 0.8267 pm 0.0573\n",
            "Wine:\n",
            "Passive: 0.9222 pm 0.0593\n",
            "SASLA: 0.9889 pm 0.0136\n",
            "ALUS: 0.9500 pm 0.0478\n",
            "Cancer:\n",
            "Passive: 0.9228 pm 0.0187\n",
            "SASLA: 0.9333 pm 0.0070\n",
            "ALUS: 0.9544 pm 0.0102\n",
            "Diabbetes:\n",
            "Passive: 3330.9931 pm 176.9137\n",
            "SASLA: 3219.7515 pm 81.9838\n",
            "Friedman:\n",
            "Passive: 3479.9149 pm 249.6106\n",
            "SASLA: 3211.2862 pm 289.1304\n",
            "Synthetic:\n",
            "Passive: 1567.2183 pm 294.4929\n",
            "SASLA: 1359.6772 pm 250.1591\n"
          ]
        }
      ],
      "source": [
        "print('Iris:')\n",
        "passive_final = [trial[1][-1] for trial in iris_passive_results]\n",
        "sasla_final = [trial[1][-1] for trial in iris_sasla_results]\n",
        "alus_final = [trial[1][-1] for trial in iris_alus_results]\n",
        "print(f'Passive: {np.mean(passive_final):.4f} pm {np.std(passive_final):.4f}')\n",
        "print(f'SASLA: {np.mean(sasla_final):.4f} pm {np.std(sasla_final):.4f}')\n",
        "print(f'ALUS: {np.mean(alus_final):.4f} pm {np.std(alus_final):.4f}')\n",
        "\n",
        "print('Wine:')\n",
        "passive_final = [trial[1][-1] for trial in wine_passive_results]\n",
        "sasla_final = [trial[1][-1] for trial in wine_sasla_results]\n",
        "alus_final = [trial[1][-1] for trial in wine_alus_results]\n",
        "print(f'Passive: {np.mean(passive_final):.4f} pm {np.std(passive_final):.4f}')\n",
        "print(f'SASLA: {np.mean(sasla_final):.4f} pm {np.std(sasla_final):.4f}')\n",
        "print(f'ALUS: {np.mean(alus_final):.4f} pm {np.std(alus_final):.4f}')\n",
        "\n",
        "print('Cancer:')\n",
        "passive_final = [trial[1][-1] for trial in cancer_passive_results]\n",
        "sasla_final = [trial[1][-1] for trial in cancer_sasla_results]\n",
        "alus_final = [trial[1][-1] for trial in cancer_alus_results]\n",
        "print(f'Passive: {np.mean(passive_final):.4f} pm {np.std(passive_final):.4f}')\n",
        "print(f'SASLA: {np.mean(sasla_final):.4f} pm {np.std(sasla_final):.4f}')\n",
        "print(f'ALUS: {np.mean(alus_final):.4f} pm {np.std(alus_final):.4f}')\n",
        "\n",
        "print('Diabbetes:')\n",
        "passive_final = [trial[1][-1] for trial in diabetes_passive_results]\n",
        "sasla_final = [trial[1][-1] for trial in diabetes_sasla_results]\n",
        "print(f'Passive: {np.mean(passive_final):.4f} pm {np.std(passive_final):.4f}')\n",
        "print(f'SASLA: {np.mean(sasla_final):.4f} pm {np.std(sasla_final):.4f}')\n",
        "\n",
        "print('Friedman:')\n",
        "passive_final = [trial[1][-1] for trial in friedman_passive_results]\n",
        "sasla_final = [trial[1][-1] for trial in friedman_sasla_results]\n",
        "print(f'Passive: {np.mean(passive_final):.4f} pm {np.std(passive_final):.4f}')\n",
        "print(f'SASLA: {np.mean(sasla_final):.4f} pm {np.std(sasla_final):.4f}')\n",
        "\n",
        "print('Synthetic:')\n",
        "passive_final = [trial[1][-1] for trial in synth_passive_results]\n",
        "sasla_final = [trial[1][-1] for trial in synth_sasla_results]\n",
        "print(f'Passive: {np.mean(passive_final):.4f} pm {np.std(passive_final):.4f}')\n",
        "print(f'SASLA: {np.mean(sasla_final):.4f} pm {np.std(sasla_final):.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
